\section{Interleaving Method}
To compute multi-scalar multiplication, e.g. $[m]P_1+[n]P_2$,
the simplest approach is to individually perform twi single-scalar multiplications,
one for $[m]P_1$ and one for$[n]P_2$, then add those results together.
If the cost for computing single-scalar multiplication using double-and-add algorithm
for $[m]P_1$ is $d_1$ doublings plue $a_1$ additions and for $[n]P_2$ is $d_2$ doubling plus $a_2$ additions,
it is easy to see that the total cost for computing $[m]P_1 + [n]P_2$ is $d_1 + d_2$ doublings plus $a_1 + a_2 + 1$ additions.

Since what needed to be computed is the sum of $[m]P_1$ and $[n]P_2$, not the individual $[m]P_1$ and $[n]P_2$,
a better way to compute this multi-scalar multiplication is to mutually perform doubling on both $m$ and $n$
then followed by individual additions for $m$ and $n$.
This interleaving method reduces the total cost to compute $[m]P_1 + [n]P_2$ down to
$max(d_1,d_2)$ doublings plus $a_1 + a_2 + 1$ additions.
See \cite{DI08} for more details.

\example{Interleaving double-and-add} \\
Let $m = m_\ell \dots m_1 m_0 = {100101}_2$ and $n = n_\ell \dots n_1 n_0 = {011001}_2$.
The $i$-bit of $m$ and $n$ denote by $m_i$ and $n_i$ respectively.
Let the result of $[m]P_1 + [n]P_2$ be kept in $R$.
The computation starts by initializing $R$ to $[m_5]P_1 + [n_5]P_2 = [1]P_1 + [0]P_2 = P_1$.
Then iterate $i$ from $4$ down to $0$, and perform $[2]R + [m_i]P_1 + [n_i]P_2$ at each step if $[m_i]$ or $[n_i]$ is non-zero: \\
$i=4; \quad R = 2(P_1) + [1]P_2 = 2P_1 + P_2$ \\
$i=3; \quad R = 2(2P_1 + [1]P_2) + P_2 = 4P_1 + 3P_2$ \\
$i=2; \quad R = 2(4P_1 + 3P_2) + [1]P_1 = 9P_1 + 6P_2$ \\
$i=1; \quad R = 2(9P_1 + 6P_2) = 18P_1 + 12P_2$ \\
$i=0; \quad R = 2(18P_1 + 12P_2) + [1]P_1 + [1]P_2 = 37P_1 + 25P_2$ \\

In this Section, we introduce two algorithms based on the interleaving method,
namely, interleaving signed sliding window and interleaving Double-Base Number System (DBNS).
The former is to combine signed sliding window with interleaving method.
This algorithm is suitable for number represented in binary format.
The latter is to combine constrained DBNS with interleaving method.
This algorithm is suitable for number represented in binary-ternary format.



\subheading{Interleaving signed sliding window} \\
\label{sec:signedslide}
The speed leading algorithm for computing single-scalar multiplication is double-and-add with signed sliding window.
The idea of signed sliding window is to precompute a set $S = \{[1]P, [3]P, [5]P, \dots, [2^{\omega}-1]P\}$ where $\omega$ is the window size.
When performing double-and-add, instead of scanning one bit and perform addition,
sliding window keep scanning bits (together perform doubling) until non-zero bit is reach.
From that non-zero bit and within the window width $\omega$, choosing the largest number and perform a single addition.
Then repeat the process of (consecutive) doubling(s) and (single) addition until the last bit is reached.
Note that the main advantage of this method is that it allows many bits (up to $\omega$ bits) to be added at one time.

In this Subsection, we will explain how signed sliding window method can be applied to compute multi-scalar multiplication combining with interleaving method.
The algorithm is very straightforward.  Let use the same example of computing multi-scalar multiplication of $[m]P_1 + [n]P_2$.
Similar to the interleaving method, doubling is mutually performed for both $m$ and $n$ while addition is individually performed for $m$ and $n$.
On top of that, we allow a number to be add to be chosen from precompute set $S_1 = \{[1]P_1, [3]P_1, \dots, [2^{\omega}-1]P_1\}$
and set $S_2 = \{[1]P_2, [3]P_2, \dots, [2^{\omega}-1]P_2\}$.
A selection of which number to be added is similar to the sliding window method that keep sliding and finding a number withing width $\omega$ and is in the precomputation sets.

Let ${\it{FindIndex}}(b,p)$ be a function performing a sliding window of width $\omega$ scanning a bit string $b$ from position $p$ to the right.
This function returns positions $i$ and $j$ closest to $p$ where $b_i$ and $b_j$ are 1 and $(b_i b_{i-1}\ dots b_j)$ is the largest in the precomputation set,
meaning that he difference between $i$ and $j$, namely, $i-j$ must not exceed the window width $\omega$.
The value $i$ and $j$ may be the same if there is only one bit set within the width $\omega$.

Let $R$ keeps the result of $[m]P_1 + [n]P_2$.  The computation starts by initializing $R$ to $0$ and call function $FindIndex$ twice for $m$ and $n$
which it returns $(i_i,j_1)$ and $(i_2,j_2)$ respectively.
Then scan each bit in both $m$ and $n$ from left to right together with performing doubling on $R$.
Let $k$ denote the current position that bits being scanned.
If $k$ is equal to $j_1$, then $m_{i_1} \dots m_{{j_1}+1} m_{j_1}$ is also added to $R$ and $FindIndex(m,j_1-1)$ is called.
Likewise, if $k$ is equal to $j_2$, then $n_{i_2} \dots n_{{j_2}+1} n_{j_2}$ is also added to $R$ and $FindIndex(n,j_2-1)$ is called.
This interleaving signed sliding window algorithm is shown in Algorithm~\ref{interleaveSlidingAlgo}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Algorithm
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{algorithm}
\caption{Interleaving signed sliding window}
\begin{algorithmic}
	\Require Scalars $m={(m_{\ell_1},\dots,m_1,m_0)}_2$ and $n={(n_{\ell_2},\dots,n_1,n_0)}_2$,
		points $P_1,P_2$, and sets $S_1=\{1P_1,3P_1,5P_1,\dots,[2^{\omega}-1]P_1\}$,$S_2=\{1P_2,3P_2,5P_2,\dots,[2^{\omega}-1]P_2\}$
	\Ensure Multi-scalar multiplication computing $[m]P_1 + [n]P_2$
	\Statex
	\State Initialize $R \gets 0$
	\State $(i_1,j_1)$ $\gets$ $FindIndex(m,\ell_1)$		\Comment{$FindIndex(b,p)$ returns ($i,j$)}
	\State $(i_2,j_2)$ $\gets$ $FindIndex(n,\ell_2)$		\Comment{where $p {\ge} i {\ge} j, i{-}j {\le} \omega$ and $b_i{,}b_j {=} 1$}
	\If{$j_1 > j_2$} \State $k \gets j_1$
	\Else \State $k \gets j_2$
	\EndIf
	\While {$k > 0$}
		\State $R$ $\gets$ $[2]R$
		\If {$k = j_1$}
			\State Set $u$ $\gets$ ${(m_{i_1},\dots,m_{j_1+1},m_{j_1})}_2$
			\State $R$ $\gets$ $R + [u]P_1$		\Comment{$[u]P_1$ obtained from set $S_1$}
			\State $(i_1,j_1)$ $\gets$ $FindIndex(m,j_1{-}1)$
		\EndIf
		\If {$k = j_2$}
			\State Set $u$ $\gets$ ${(n_{i_2},\dots,n_{j_2+1},n_{j_2})}_2$
			\State $R$ $\gets$ $R + [u]P_2$		\Comment{$[u]P_2$ obtained from set $S_2$}
			\State $(i_2,j_2)$ $\gets$ $FindIndex(n,j_2{-}1)$
		\EndIf
		\State $k$ $\gets$ $k - 1$
	\EndWhile
	\\ \Return $[m]P_1 + [n]P_2$
\end{algorithmic}
\label{interleaveSlidingAlgo}
\end{algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\example{Interleaving signed sliding window} \\
Let $m = m_\ell \dots m_1 m_0 = {100101}_2$ and $n = n_\ell \dots n_1 n_0 = {011001}_2$.
Let $(m_{i_1,j_1})$ and $(n_{i_2,j_2})$ denote $m_{i_1} m_{i_1-1} \dots m_{j}$ and $n_{i_2} n_{i_2-1} \dots n_{j_2}$ respectively.
Let the result of $[m]P_1 + [n]P_2$ be kept in $R$ and let the window width $\omega = 3$.
The computation starts by scanning from $m_\ell$ and find $(m_{i_1,j_1})$ such that $m_{i_1} = m_{j_1} = 1$ and $i_1 - j_1 \le \omega$.
Repeat this with $n$ as well.
In this example, $(m_{i_1,j_1}) = (m_{5,5})$ and $(n_{i_2,j_2}) = (n_{4,3})$.
Because $j_1 > j_2$, $R$ is initialized to $[(m_{5,5})]P_1 = P_1$.
The computation continues by iterating $k$ from $4$ down to $0$.
At each step perform $[2]R$, and if $j_1 = i$ then add $[(m_{i_1,j_1})]P_1$ to $R$, and if $j_2 = i$ then also add $[(n_{i,j_2})]P_2$ to $R$: \\
$k=4; \quad R = 2(P_1) = 2P_1$ \\
$k=3; \quad R = 2(2P_1) + 3P_2 = 4P_1 + 3P_2$ \\
$k=2; \quad R = 2(4P_1 + 3P_2) = 8P_1 + 6P_2$ \\
$k=1; \quad R = 2(8P_1 + 6P_2) = 16P_1 + 12P_2$ \\
$k=0; \quad R = 2(16P_1 + 12P_2) + 5P_1 + P_2 = 37P_1 + 25P_2$ \\


To illustrate the performance of this interleaving signed sliding window algorithm,
we conducted experiments using randomly chosen $10000$ pairs of integers $m$ and $n$.
We used various bit range, namely, 192, 256, 320, 384, 448, and 512.
We also tried using different window widths range from $0$ to $10$.
The performance is measured by the number of multiplication ($N_M$) required to compute $[m]P_1 + [n]P_2$.
To gain the best speed from both doubling and addition, we use mixed coordinate systems,
namely, projective twisted Edwards and extend twisted Edwards with $a=-1$
With this curve choice, a doubling takes $3\mul + 4\sqr$, a regular addition takes $8\mul$, and a mixed addition takes $7\mul$
where $\mul$ and $\sqr$ denote field multiplication and field squaring respectively.
We also use a common assumption that $\sqr \approx 0.8\mul$.
Note that we perform conversion in order to make precomputation points in affine so that a faster mixed addition can be used.
The cost displays in Table~\ref{signedslideTable} does include the cost of precomputation but exclude the cost of conversion.
The notation {$\mathcal{\#P}$} denotes the number of precomputation points.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Table
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[h]
\centering
\begin{tabular}{|C{0.1\textwidth}| *6{C{0.06\textwidth} C{0.06\textwidth}|} }
%\begin{tabularx}{\textwidth}{|X| *6{X X|}}
\toprule
%\hline
\multirow{2}{*}{width $\omega$}
	&\multicolumn{2}{c|}{192-bit}
		&\multicolumn{2}{c|}{256-bit}
			&\multicolumn{2}{c|}{320-bit}
				&\multicolumn{2}{c|}{384-bit}
					&\multicolumn{2}{c|}{448-bit}
						&\multicolumn{2}{c|}{512-bit} \\
	&\tiny{$N_M$}	&\tiny{$\mathcal{\#P}$}
		&\tiny{$N_M$}	&\tiny{$\mathcal{\#P}$}
			&\tiny{$N_M$}	&\tiny{$\mathcal{\#P}$}
				&\tiny{$N_M$}	&\tiny{$\mathcal{\#P}$}
					&\tiny{$N_M$}	&\tiny{$\mathcal{\#P}$}
						&\tiny{$N_M$}	&\tiny{$\mathcal{\#P}$} \\
\midrule
\input{table_signedslide}
%\hrule
\bottomrule
\multicolumn{13}{c}{}
%\end{tabularx}
\end{tabular}
\caption{Number of multiplications and precomputation points for different window widths to compute multi-scalar multiplication using interleaving signed sliding window}
\label{signedslideTable}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


We observed that the optimal window width $\omega = 5$.
However, this width requires approximately 20-22 precomputation points on average
which might casuse troubles in limited memory environment.
A reasonable choice of width would be $\omega = 4$ which still provides good performance
and only requires 10 precomputation points to be kept.



\subheading{Interleaving DBNS} \\
In case of tripling operation is also available in addition to doubling and addition operations,
scalars can be represented using $\{2,3\}$ Double-Base Number System (DBNS)
$$n = \Sigma^{\ell}_{i=1} c_i 2^{a_i}3^{b_i} \text{, where $c_i \in \{-1,1\}$ }.$$
That is, terms in a number expansion consist of power of two and three.

\example{Double-Base Number System} \\
$542788 = 2^83^7 - 2^33^7 + 2^43^3 - 2^13^3 - 2$

The main advantage of DBNS over binary representation is that the number of terms in the expansion is smaller.
However, the main drawback of DBNS is that scalar multiplication cannot be performed using Horner-like method.
Therefore, the cost of doubling is at least $max(a_i)$.  Similarly, the cost of tripling is at least $max(b_i)$.

In \cite{DIM05}, a restrictive DBNS called {\it{double-base chain}} (DBC) was introduced.
Exponents $a_i$ and $b_i$ in the expansion can no long be freely chosen but have to obey the restrictions
$a_\ell \ge a_{\ell-1)} \ge \cdots \ge a_1$ and $b_\ell \ge b_{\ell-1} \ge \cdots \ge b_1$.
These extra conditions on the exponents increase the number of terms in the expansion.
With these restrictions, Horner-like method can be applied to DBC when computing scalar multiplication, e.g.,
$$[841232]P = [3]([3]([3]([2^13^3]([2^63^2]P+P)-P)-P)+P)-P.$$
Unlike DBNS, the cost of doubling and tripling for DBC is guaranteed to be at most $max(a_i)$ and $max(b_i)$.

In \cite{MH09}, M\'eloni and Hasan proposed an algorithm for number represented in DBNS to perform scalar multiplication
in which Horner-like method can still be applicable.
Their idea was to precompute a set containing power of $2$ and apply the Horner-like method only on power of $3$.
The drawback of this algorithm is that it has large amount of precomputation points.

Inspried by that idea, we took a similar approach of using DBNS and try to make it applicable for Horner-like method.
Our approach is, instead of forcing the degree of both exponents $a_i$ and $b_i$ to be in decreasing order,
we force only the degree of exponent $a_i$ to be in decreasing order.
The degree of exponent $b_i$ can be in any order but must not exceed a bound $b^{max}$.
In other words, the restriction becomes
$a_\ell \ge a_{\ell-1} \ge \cdots \ge a_1$ (same as DBC) and $b_1,b_2,\dots,b_\ell \le b^{max}$ (different from DBC).
This way, Horner-like method can now applied to exponent $a_i$.

\example{Apply Horner-like method to DBNS on single exponent} \\
\\
$[983828]P = [2^43^{10}]P - [2^23^4]P + [2^13^9]P + [2^1]P$ \\
$\phantom{[983828]P} = [2]([2^33^{10}]P - [2^13^4]P + [3^9]P + P)$ \\
$\phantom{[983828]P} = [2]([2]([2^23^{10}]P - [3^4]P) + [3^9]P + P)$ \\
\\
Note that $[3^4]P, [3^9]P, [3^{10}]P$ need to be precomputed. \\

In this Subsection, we will explain how to combine the new restricted DBNS with the interleaving method to compute multi-scalar multiplication.
The essential part to compute $[m]P_1 + [n]P_2$ giving a bound $b^{max}$ on the maximum power of 3
is to find a good $\{2,3\}$-DBNS representation for $m$ and $n$.
At each step, we find two approximations, namely, one closest $m$ and the other one closest to $n$.
Then we choose the best one between these two that give the best approximation to both $m$ and $n$ and subtract from them.
Continue to iterate these steps until $m$ and $n$ reach $0$.
This algorithm requires $2 \times b^{max}$ of precomputation points and $2 \times b^{max}$ triplings are used in the precomputation.
The main computation consists of only doublings and additions.
Algorithm~\ref{interleaveDBNSChainAlgo} shows the interleaving DBNS algorithm to obtain a $\{2,3\}$-DBNS.

\example{Generating chain for interleaving DBNS} \\
Let $m = 554627$, $n = 748556$ and $b^{max} = 5$. \\
At each step, let $(a_i,b_i,c_i,d_i)$ where $b_i \le 5$ makes $2^{a_i}3^{b_i}$ the best approximation of $m$ and $n$. \\
$(a_0,b_0) = (18,\phantom{0}1,\phantom{-}0,\phantom{-}1)$;		$\quad n\phantom{m} = \phantom{-}748556			- 2^{18}3^{1}		= -37876$ \\
$(a_1,b_1) = (19,\phantom{0}0,\phantom{-}1,\phantom{-}0)$;		$\quad m\phantom{n} = \phantom{-}554627			- 2^{19}3^{0}		= \phantom{-}30339$ \\
$(a_2,b_2) = (12,\phantom{0}2,\phantom{-}0,-1)$;			$\quad n\phantom{m} = -37876\phantom{0}			+ 2^{12}3^{2}		= -1012$ \\
$(a_3,b_3) = (\phantom{0}7,\phantom{0}5,\phantom{-}1,\phantom{-}0)$; 	$\quad m\phantom{n} = \phantom{-}30339\phantom{0}	- 2^{\phantom{0}7}3^{5} = -765$ \\
$(a_4,b_4) = (10,\phantom{0}0,\phantom{-}0,-1)$;			$\quad n\phantom{m}=  -1012\phantom{00}			+ 2^{10}3^{0}		= \phantom{-}12$ \\
$(a_5,b_5) = (\phantom{0}8,\phantom{0}1,-1,\phantom{-}0)$; 		$\quad m\phantom{n}=  -765\phantom{000}			+ 2^{\phantom{0}8}3^{1} = \phantom{-}3$ \\
$(a_6,b_6) = (\phantom{0}2,\phantom{0}1,\phantom{-}0,\phantom{-}1)$; 	$\quad n\phantom{m}= \phantom{-}12\phantom{0000}	- 2^{\phantom{0}2}3^{1} = \phantom{-}0$ \\
$(a_7,b_7) = (\phantom{0}0,\phantom{0}1,\phantom{-}1,\phantom{-}0)$; 	$\quad m\phantom{n}= \phantom{-}3\phantom{00000}	- 2^{\phantom{0}0}3^{1} = \phantom{-}0$ \\
Therefore, an interleaving DBNS chain: \\
\\
$[554627]P_1 + [748556]P_2 = [2^{18}3^{1}]P_2 + [2^{19}3^{0}]P_1 - [2^{12}3^{2}]P_2 \\
\phantom{[554627]P_1 + [748556]P_2 =}
			+ [2^{7}3^{5}]P_1 - [2^{10}]P_2 - [2^{8}3^{1}]P_1 \\
\phantom{[554627]P_1 + [748556]P_2 =}
			+ [2^{2}3^{1}]P_2 + [2^{0}3^{1}]P_1$. \\
\\
Apply Horner-like method to the power of $2$, then $[554627]P_1 + [748556]P_2$ can be computed as: \\
\\
$[2^2]([2^5]([2]([2^2]([2^2]([2^6]([2]P_1 + [3^1]P_2) - [3^2]P_2) - [3^0]P_2) \\
\phantom{[2^2]([2^5]([2]([2^2]([2^2]([2^6]([2]P_1}
- [3^1]P_1) + [3^5]P_1) + [3^1]P_2) + [3^1]P_1.$ \\
\\
Note: points need to be precomputed are: $[3]P_1, [3^5]P_1, [3]P_2, [3^2]P_2$. \\


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Algorithm
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{algorithm}
\caption{Generating chain for interleaving DBNS}
\begin{algorithmic}
	\Require Scalars $m, n$ and a bound $b^{max}$
	\Ensure	A $\{2,3\}$-DBNS representing $m+n$
	\Statex
	\State Initialize $chain \gets [ ]$
	\While {$m \ne 0$ or $n \ne 0$}
		\State $(a,b,c,d) \gets FindTerm(m,n)$
		\State $m\phantom{n} \gets m - c2^a3^b$
		\State $n\phantom{m} \gets n - d2^a3^b$
		\State $chain \gets chain.append(a,b,c,d)$
	\EndWhile
	\\ \Return $chain$
\end{algorithmic}

\begin{algorithmic}
	\Statex
	\State {\bf{FindTerm($r_1,r_2$):}}
	\State Initialize $min_1 \gets \infty$, $min_2 \gets \infty$
	\For {$0 \le a_i \le a^{max}$ and $0 \le b_i \le b^{max}$}
		\State $d_1 \gets |r_1 - 2^{a_i}3^{b_i}|$
		\If {$d_1 < min_1$}
			\State $min_1 \gets d_1$
			\State $pair_1 \gets (a_i,b_i,sgn(r_1),0)$	\Comment{$sgn(n) = 0$ if $n = 0$; otherwise $sgn(n) = \frac{|n|}{n}$}
		\EndIf
		\State $d_2 \gets |r_2 - 2^{a_i}3^{b_i}|$
		\If {$d_2 < min_2$}
			\State $min_2 \gets d_2$
			\State $pair_2 \gets (a_i,b_i,0,sgn(r_2))$
		\EndIf
	\EndFor
	\If {$min_1^2 + r_2^2 <  r_1^2 + min_2^2$}
		$(a,b,c,d) \gets pair_1$
	\Else
		$(a,b,c,d) \gets pair_2$
	\EndIf
	\\ \Return $(a,b,c,d)$
\end{algorithmic}

\label{interleaveDBNSChainAlgo}
\end{algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Algorithm
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{algorithm}
%\caption{Interleaving DBNS}
%\begin{algorithmic}
%	\Require A $chain$ $\{2,3\}$-DBNS Chain representing $m + n$, points $P_1$ and $P_2$
%	\Ensure Multi-scalar multiplication computing $[m]P_1 + [n]P_2$
%	\Statex
%	\State Initialize $R \gets 0$
%	\For {$x$ in $chain$}
%		\State $R \gets [2]R$
%	\EndFor
%	\\ \Return $R$
%\end{algorithmic}
%\label{interleaveDBNSSmultAlgo}
%\end{algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


To show the performance of the interleaving DBNS algorithm,
we conducted several experiments and summarized data in Table~\ref{dbnsTable}.
We tested different $b^{max}$ values from $0$ to $15$.
The setting of the experiment  was similar to the one on interleaving signed sliding window ~\ref{sec:signedslide},
namely, we used $10000$ randomly chosen pairs of integers $m$ and $n$ for bit range 192, 256, 320, 384, 448 an 512.
We use the same mixed coordinate systems projective and extended twisted Edwards with $a=-1$.

We also used tripling formulas in this experiment.
Since tripling is used for computing precomputation points which will be added,
outputs of tripling have to be in extend coordinates.
Therefore tripling takes $11\mul + 3\sqr$.  Again, we use a common assumption that $\sqr \approx 0.8\mul$.
Note again that we perform conversion in order to make precomputation point in affine so that a faster mixed addition formulas can be used.
The cost displays in Table~\ref{dbnsTable} does include the cost of precomputation but exclude the cost of conversion.
The notation {$\mathcal{\#P}$} denotes the number of precomputation points.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Table
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[h]
\centering
\begin{tabular}{|C{0.1\textwidth}| *6{C{0.06\textwidth} C{0.06\textwidth}|} }
%\begin{tabularx}{\textwidth}{|X| *6{X X|}}
\toprule
%\hline
\multirow{2}{*}{$b^{max}$}
	&\multicolumn{2}{c|}{192-bit}
		&\multicolumn{2}{c|}{256-bit}
			&\multicolumn{2}{c|}{320-bit}
				&\multicolumn{2}{c|}{384-bit}
					&\multicolumn{2}{c|}{448-bit}
						&\multicolumn{2}{c|}{512-bit} \\
	&\tiny{$N_M$}	&\tiny{$\mathcal{\#P}$}
		&\tiny{$N_M$}	&\tiny{$\mathcal{\#P}$}
			&\tiny{$N_M$}	&\tiny{$\mathcal{\#P}$}
				&\tiny{$N_M$}	&\tiny{$\mathcal{\#P}$}
					&\tiny{$N_M$}	&\tiny{$\mathcal{\#P}$}
						&\tiny{$N_M$}	&\tiny{$\mathcal{\#P}$} \\
\midrule
\input{table_dbns}
%\hrule
\bottomrule
\multicolumn{13}{c}{}
%\end{tabularx}
\end{tabular}
\caption{Number of multiplications and precomputation points for different $b^{max}$ to compute double-scalar multiplication using interleaving DBNS}
\label{dbnsTable}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The experimental results suggest that setting $b^{max} = 6$ or having $12$ precomputation points gives the best performance for 192- and 256-bit.
The $b^{max}$ value increase as the bit size increase, meaning that more space to keep precomputation points is required as the bit size grows
in order to gain a good performance.




